{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Densnet-121 torch.Size([1, 1000])\n",
      "Num Parameters: 7976744\n",
      "DenseNet-169 torch.Size([1, 1000])\n",
      "Num Parameters: 14146088\n",
      "DenseNet-201 torch.Size([1, 1000])\n",
      "Num Parameters: 20010024\n",
      "DenseNet-264 torch.Size([1, 1000])\n",
      "Num Parameters: 33332264\n"
     ]
    }
   ],
   "source": [
    "class BNReluConvBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0):\n",
    "        \"\"\"DenseNet building block consisting of BatchNorm -> ReLU -> Conv.\n",
    "        Args:\n",
    "            in_channels: number of input channels.\n",
    "            out_channels: number of output channels.\n",
    "            kernel_size: size of the convolving kernel.\n",
    "            stride: stride of the convolution.\n",
    "            padding: zero-padding added to both sides of the input.\n",
    "        \"\"\"\n",
    "        super(BNReluConvBlock, self).__init__()\n",
    "        self.bn = torch.nn.BatchNorm2d(in_channels)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)  # inplace=True to save memory\n",
    "        # no need in bias because of the BatchNorm\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n",
    "                                    stride=stride, padding=padding, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(self.relu(self.bn(x)))\n",
    "\n",
    "class DenseLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, bn_size=4):\n",
    "        \"\"\"\n",
    "        A DenseLayer consists of BN -> ReLU -> Conv1x1 -> BN -> ReLU -> Conv3x3.\n",
    "        Args:\n",
    "            in_channels: number of input channels.\n",
    "            growth_rate: how many channels the layer will add.\n",
    "            bn_size: bottleneck size multiplier. default is 4.\n",
    "        \"\"\"\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.bn_relu_conv1 = BNReluConvBlock(in_channels, growth_rate * bn_size, kernel_size=1)\n",
    "        self.bn_relu_conv2 = BNReluConvBlock(growth_rate * bn_size, growth_rate, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.bn_relu_conv1(x)\n",
    "        new_features = self.bn_relu_conv2(bottleneck)\n",
    "        return new_features   # Return only the new features (B, growth_rate, H, W)\n",
    "\n",
    "class DenseBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers, bn_size=4):\n",
    "        \"\"\"\n",
    "        A DenseBlock stacks num_layers of Dense layers consiting of \n",
    "        BN -> ReLU -> Conv1x1 -> BN -> ReLU -> Conv3x3.\n",
    "        Args:\n",
    "            num_layers: number of layers in the block (e.g., 6, 12, 32, or 32).\n",
    "            in_channels: number of input channels.\n",
    "            growth_rate: how many channels each layer will add.\n",
    "            bn_size: bottleneck size multiplier. default is 4.\n",
    "        \"\"\"\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(DenseLayer(in_channels + i * growth_rate, growth_rate, bn_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        for dense_layer in self.layers:\n",
    "            #here we concatenate the input with the features from the previous layers\n",
    "            new_feature = dense_layer(torch.cat(features, 1)) \n",
    "            features.append(new_feature) \n",
    "        return torch.cat(features, 1) # concatenate all the features (channels) from the layers\n",
    "\n",
    "class TransitionLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, theta=0.5):\n",
    "        \"\"\"\n",
    "        A TransitionLayer downsamples the spatial size by 2 and reduces the number of channels by theta.\n",
    "        Args:\n",
    "            in_channels: number of input channels.\n",
    "            theta: compression factor. default is 0.5.\n",
    "        \"\"\"\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        out_channels = int(in_channels * theta)\n",
    "        self.bn_relu_conv = BNReluConvBlock(in_channels, out_channels, kernel_size=1)\n",
    "        self.avg_pool = torch.nn.AvgPool2d(kernel_size=2, stride=2) # reduce the spatial size by 2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.avg_pool(self.bn_relu_conv(x))\n",
    "\n",
    "class DenseNet(torch.nn.Module):\n",
    "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16), num_classes=1000, bn_size=4, theta=0.5):\n",
    "        \"\"\" A DenseNet model.\n",
    "\n",
    "        Args:\n",
    "            growth_rate: how many channels each layer will add. (k in the paper, e.g., 32 for DenseNet-121)\n",
    "            block_config: a list of numbers of layers in each block. (e.g., (6, 12, 24, 16) for DenseNet-121)\n",
    "            num_classes: number of classes in the dataset. Default is 1000 for ImageNet.\n",
    "            bn_size: bottleneck size multiplier. Default is 4. (1x1 Conv layer before 3x3 Conv layer)\n",
    "            theta: compression factor. Default is 0.5. (0.5 means 50% of the channels will be dropped)\n",
    "        \"\"\"\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        # initial convolution layer\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3) # 224x224x3 -> 112x112x64 (224-7 + 2*3)/2 + 1 = 112\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1) # 112x112x64 -> 56x56x64 (112-3+2)/2+1=56\n",
    "\n",
    "        num_channels = 64\n",
    "        self.net = torch.nn.Sequential()\n",
    "\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            dense_block = DenseBlock(num_channels, growth_rate, num_layers, bn_size)\n",
    "            self.net.add_module(f'dense_block{i + 1}', dense_block)\n",
    "            num_channels += num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans_layer = TransitionLayer(num_channels, theta)\n",
    "                self.net.add_module(f'trans_layer{i + 1}', trans_layer)\n",
    "                num_channels = int(num_channels * theta) # half the number of channels            \n",
    "\n",
    "        # For myself to understand the code\n",
    "        # self.dense1 = DenseBlock(64, growth_rate, block_config[0], bn_size=bn_size) # returns 56x56x64 + 6*32 = 56x56x256\n",
    "        # self.trans1 = TransitionLayer(64 + block_config[0] * growth_rate, theta) # 56x56x256 -> 28x28x128 with theta=0.5\n",
    "\n",
    "        # self.dense2 = DenseBlock(128, growth_rate, block_config[1], bn_size=bn_size) # 28x28x128 + 12*32 = 28x28x512\n",
    "        # self.trans2 = TransitionLayer(128 + block_config[1] * growth_rate, theta) # 28x28x512 -> 14x14x256 with theta=0.5\n",
    "\n",
    "        # self.dense3 = DenseBlock(256, growth_rate, block_config[2], bn_size=bn_size) # 14x14x256 + 24*32 = 14x14x1024\n",
    "        # self.trans3 = TransitionLayer(256 + block_config[2] * growth_rate, theta) # 14x14x1024 -> 7x7x512 with theta=0.5\n",
    "\n",
    "        # self.dense4 = DenseBlock(512, growth_rate, block_config[3], bn_size=bn_size) # 7x7x512 + 16*32 = 7x7x1024\n",
    "\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1)) # 7x7x1024 -> 1x1x1024\n",
    "        self.fc = torch.nn.Linear(num_channels, num_classes) # 1024 -> num_classes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "        x = self.net(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "# create a DenseNet-121 model\n",
    "model = DenseNet(growth_rate=32, block_config=(6, 12, 24, 16), num_classes=1000, bn_size=4, theta=0.5)\n",
    "print('Densnet-121', model(torch.randn(1, 3, 224, 224)).shape)\n",
    "print(f'Num Parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "\n",
    "# create a DenseNet-169 model\n",
    "model = DenseNet(growth_rate=32, block_config=(6, 12, 32, 32), num_classes=1000, bn_size=4, theta=0.5)  \n",
    "print('DenseNet-169', model(torch.randn(1, 3, 224, 224)).shape)\n",
    "print(f'Num Parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "\n",
    "# create a DenseNet-201 model\n",
    "model = DenseNet(growth_rate=32, block_config=(6, 12, 48, 32), num_classes=1000, bn_size=4, theta=0.5)\n",
    "print('DenseNet-201', model(torch.randn(1, 3, 224, 224)).shape)\n",
    "print(f'Num Parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "\n",
    "# create a DenseNet-264 model\n",
    "model = DenseNet(growth_rate=32, block_config=(6, 12, 64, 48), num_classes=1000, bn_size=4, theta=0.5)\n",
    "print('DenseNet-264', model(torch.randn(1, 3, 224, 224)).shape)\n",
    "print(f'Num Parameters: {sum(p.numel() for p in model.parameters())}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-50 torch.Size([1, 1000])\n",
      "Num Parameters: 25557032\n",
      "ResNet-101 torch.Size([1, 1000])\n",
      "Num Parameters: 44549160\n",
      "ResNet-152 torch.Size([1, 1000])\n",
      "Num Parameters: 60192808\n",
      "ResNet-200 torch.Size([1, 1000])\n",
      "Num Parameters: 64673832\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ConvBNReluBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0):\n",
    "        \"\"\"ResNet building block consisting of Conv -> BatchNorm -> ReLU.\n",
    "\n",
    "        Args:\n",
    "            in_channels: number of input channels.\n",
    "            out_channels: number of output channels.\n",
    "            kernel_size: kernel size of the convolution.\n",
    "            stride: stride of the convolution.\n",
    "            padding: padding of the convolution.\n",
    "        \"\"\"\n",
    "        super(ConvBNReluBlock, self).__init__()\n",
    "        # bias=False because of the BatchNorm\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.relu = torch.nn.ReLU(inplace=True) # inplace=True to save memory\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class BottleneckLayer(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, expansion=4, stride=1):\n",
    "        \"\"\" A ResNet bottleneck layer consisting of 3 conv layers.\n",
    "        Conv1x1 -> Conv3x3 -> Conv1x1.\n",
    "        Args:\n",
    "           in_channels: Number of input channels.\n",
    "           out_channels: Number of channels before expansion.\n",
    "           expansion: Factor to scale the number of channels. \n",
    "                    For bottleneck design, the number of output channels is scaled by 'expansion'\n",
    "           stride: Stride of the second conv layer.\n",
    "        \"\"\"\n",
    "        super(BottleneckLayer, self).__init__()\n",
    "        # 1x1 Convolution\n",
    "        self.conv_bn_relu1 = ConvBNReluBlock(in_channels, out_channels, kernel_size=1)\n",
    "        # 3x3 Convolution\n",
    "        self.conv_bn_relu2 = ConvBNReluBlock(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        # 1x1 Convolution\n",
    "        self.conv_bn_relu3 = ConvBNReluBlock(out_channels, out_channels * expansion, kernel_size=1)\n",
    "\n",
    "        self.downsample = None\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * expansion:\n",
    "            self.downsample = ConvBNReluBlock(in_channels, out_channels * expansion, kernel_size=1, stride=stride)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv_bn_relu1(x)\n",
    "        out = self.conv_bn_relu2(out)\n",
    "        out = self.conv_bn_relu3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = out + identity\n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNetBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, bottleneck_channels, num_layers, expansion=4, stride=1):\n",
    "        \"\"\" A block of ResNet consisting of multiple Bottleneck layers.\n",
    "        Args:\n",
    "            in_channels: Number of input channels.\n",
    "            bottleneck_channels: Number of channels in the Bottleneck layer.\n",
    "            num_layers: Number of Bottleneck layers in the block.\n",
    "            expansion: Factor to scale the number of channels.\n",
    "            stride: Stride of the first Bottleneck layer.\n",
    "        \"\"\"\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers.append(BottleneckLayer(in_channels, bottleneck_channels, expansion=expansion, stride=stride))\n",
    "        for _ in range(1, num_layers):\n",
    "            self.layers.append(BottleneckLayer(bottleneck_channels * expansion, bottleneck_channels, expansion=expansion))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, layers=[3,4,6,3], num_classes=1000):\n",
    "        \"\"\"ResNet model with 50, 101, 152, or 200 layers.\n",
    "\n",
    "        Args:\n",
    "            layers: A list of 4 integers specifying the number of layers in each block. (e.g., [3, 4, 6, 3] for ResNet-50)\n",
    "            num_classes: Number of classes in the dataset. (e.g. 1000 for ImageNet)\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__()\n",
    "    \n",
    "        # initial convolution layer\n",
    "        self.conv_bn_relu = ConvBNReluBlock(3, 64, kernel_size=7, stride=2, padding=3) # 224x224x3 -> 112x112x64\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1) # 112x112x64 -> 56x56x64\n",
    "\n",
    "        num_channels = 64\n",
    "        expansion = 4\n",
    "\n",
    "        self.net = torch.nn.Sequential()\n",
    "\n",
    "        for i, num_layers in enumerate(layers):\n",
    "            stride = 1 if i == 0 else 2\n",
    "            bottleneck_channels = 64 * (2**i) # 64, 128, 256, 512\n",
    "            resnet_block = ResNetBlock(num_channels, bottleneck_channels, num_layers, expansion=expansion, stride=stride)\n",
    "            self.net.add_module(f'resnet_block{i + 1}', resnet_block)\n",
    "            num_channels = bottleneck_channels * expansion\n",
    "\n",
    "        # ResNet layers\n",
    "        # Written to understand the code by block\n",
    "        # self.resnet_block1 =  ResNetBlock(num_channels, 64, layers[0], stride=1) # 56x56x64 -> 56x56x256\n",
    "        # num_channels = 64 * expansion\n",
    "        # self.resnet_block2 =  ResNetBlock(num_channels, 128, layers[1], stride=2) # 56x56x256 -> 28x28x512\n",
    "        # num_channels = 128 * expansion\n",
    "        # self.resnet_block3 =  ResNetBlock(num_channels, 256, layers[2], stride=2) # 28x28x512 -> 14x14x1024\n",
    "        # num_channels = 256 * expansion\n",
    "        # self.resnet_block4 =  ResNetBlock(num_channels, 512, layers[3], stride=2) # 14x14x1024 -> 7x7x2048\n",
    "        # num_channels = 512 * expansion\n",
    "\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = torch.nn.Linear(num_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(self.conv_bn_relu(x))\n",
    "        x = self.net(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# create a ResNet-50 model\n",
    "model = ResNet(layers=[3, 4, 6, 3], num_classes=1000)\n",
    "# print(model)\n",
    "print('ResNet-50', model(torch.randn(1, 3, 224, 224)).shape)\n",
    "print(f'Num Parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "\n",
    "# create a ResNet-101 model\n",
    "model = ResNet(layers=[3, 4, 23, 3], num_classes=1000)\n",
    "print('ResNet-101', model(torch.randn(1, 3, 224, 224)).shape)\n",
    "print(f'Num Parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "\n",
    "# create a ResNet-152 model\n",
    "model = ResNet(layers=[3, 8, 36, 3], num_classes=1000)\n",
    "print('ResNet-152', model(torch.randn(1, 3, 224, 224)).shape)\n",
    "print(f'Num Parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "\n",
    "# create a ResNet-200 model\n",
    "model = ResNet(layers=[3, 24, 36, 3], num_classes=1000)\n",
    "print('ResNet-200', model(torch.randn(1, 3, 224, 224)).shape)\n",
    "print(f'Num Parameters: {sum(p.numel() for p in model.parameters())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_zero_to_hero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
